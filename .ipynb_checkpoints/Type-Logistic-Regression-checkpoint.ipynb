{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "We will use 1 vs all to train eighteen different logistic regression models with L2 regularization.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#TODO \n",
    "#read in data \n",
    "types = ['water', 'fire', 'grass', 'normal', 'electric', 'flying', 'ice', 'bug', 'poison', 'psychic', 'dark', 'steel', 'ghost', 'dragon', 'fairy', 'rock', 'ground', 'fighting']\n",
    "\n",
    "def load_data(cur_type):\n",
    "    my_data = pd.read_csv('pokemon_final.csv')\n",
    "    my_data = my_data.sample(frac=1) #randomly shuffle rows\n",
    "    train_data = my_data[:600] #data to train on\n",
    "    test_data = my_data[-206:] #data to test with\n",
    "\n",
    "    X = train_data.drop(['Name', 'Type 1', 'Type 2'], axis = 1) #features\n",
    "    #theta = np.zeros(X.shape) #weights\n",
    "    Y2 = train_data.drop(train_data.columns.difference(['Type 1', 'Type 2']), axis = 1) #actual types\n",
    "\n",
    "    X_test = test_data.drop(['Name', 'Type 1', 'Type 2'], axis = 1) #features\n",
    "    Y2_test = test_data.drop(test_data.columns.difference(['Type 1', 'Type 2']), axis = 1) \n",
    "\n",
    "\n",
    "\n",
    "    Y = np.zeros((Y2.shape[0],1)) #create the list of 1's and -1's representing current type yes or no\n",
    "    for i in range(1, Y2.shape[0]):\n",
    "        t1 = Y2[i-1:i].iloc[0]['Type 1']\n",
    "        t2 = Y2[i-1:i].iloc[0]['Type 2']\n",
    "        if t1 == cur_type or t2 == cur_type:\n",
    "            Y[i-1] = 1\n",
    "        else:\n",
    "            Y[i-1] = -1\n",
    "\n",
    "    Y_test = np.zeros((Y2_test.shape[0],1)) #create the list of 1's and -1's representing current type yes or no\n",
    "    for i in range(1, Y2_test.shape[0]):\n",
    "        t1 = Y2_test[i-1:i].iloc[0]['Type 1']\n",
    "        t2 = Y2_test[i-1:i].iloc[0]['Type 2']\n",
    "        if t1 == cur_type or t2 == cur_type:\n",
    "            Y_test[i-1] = 1\n",
    "        else:\n",
    "            Y_test[i-1] = -1\n",
    "\n",
    "\n",
    "    one_count = 0\n",
    "    negative_count = 0\n",
    "    for i in range(len(Y_test)):\n",
    "        if(Y_test[i] == 1):\n",
    "            one_count +=1\n",
    "        else:\n",
    "            negative_count+=1\n",
    "    print(\"one count:\", one_count)\n",
    "    print(\"negative count:\", negative_count)\n",
    "        \n",
    "    return X, Y, X_test, Y_test, cur_type\n",
    "\n",
    "#print(Y)\n",
    "#print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, gradient of the loss, and Hessian of the loss for logistic regression.\n",
    "\n",
    "\\begin{align*}\n",
    "L &= \\left[\\sum_{i=1}^m \\ln(1+e^{-y_ix_i^\\top w})\\right] + \\frac{\\lambda}{2}\\sum_{j=2}^n w_j^2\n",
    "\\end{align*}\n",
    "\n",
    "\\begin{align*}\n",
    "p_i &= \\sigma(y_ix_i^\\top w) \\\\\n",
    "\\tilde{w} &= \\begin{bmatrix} 0 & w_2 & w_3 & \\dots & w_n \\end{bmatrix}^\\top \\\\\n",
    "\\tilde{I} &= \\begin{bmatrix} 0 & 0 & 0 & & 0 \\\\\n",
    "                        0 & 1 & 0 & \\dots & 0 \\\\\n",
    "                        0 & 0 & 1 & & 0 \\\\\n",
    "                        & \\vdots & & \\ddots & \\vdots \\\\\n",
    "                        0 & 0 & 0 & \\dots & 1 \\end{bmatrix} \\\\\n",
    "\\nabla L &= - \\left[\\sum_{i=1}^m (1-p_i)y_i x_i^\\top\\right] + \\lambda\\tilde{w} \\\\\n",
    "H_L &= \\left[\\sum_{i=1}^m p_i(1-p_i)x_ix_i^\\top\\right] + \\lambda\\tilde{I}\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code to calculate the same here\n",
    "\n",
    "def lrloss(w,X,Y,lmbda):\n",
    "    wnob = w.copy()\n",
    "    wnob[0] = 0\n",
    "    return (np.sum(np.log(1+np.exp(-Y*(X@w))),0).T + 0.5*lmbda*np.sum(wnob*wnob))[0]\n",
    "\n",
    "def lrgrad(w,X,Y,lmbda):\n",
    "    wnob = w.copy()\n",
    "    wnob[0] = 0\n",
    "    return -np.sum((1-1/(1+np.exp(-Y*(X@w))))*X*Y,0)[:,np.newaxis] + lmbda*wnob\n",
    "\n",
    "def lrhess(w,X,Y,lmbda):\n",
    "    p = 1/(1+np.exp(-Y*(X@w)))\n",
    "    ey = np.eye(w.shape[0])\n",
    "    ey[0,0] = 0\n",
    "    R = p*(1-p)\n",
    "    return X.T@np.diag(R[:,0])@X + lmbda*ey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton-Raphson minimization.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent implemented with a constant step size\n",
    "# (note: this is *not* a good implementation, but just to show the idea)\n",
    "# The \"ittfn\" can help with debugging, but isn't necessary\n",
    "def graddesc(w,eta,fn,gradfn,ittfn=None):\n",
    "    oldf = fn(w)\n",
    "    df = 1\n",
    "    while(df>1e-6):\n",
    "        w = w - eta*gradfn(w)\n",
    "        newf = fn(w)\n",
    "        df = oldf-newf # hope to be positive, or we've over-shot and will be done\n",
    "        if ittfn is not None:\n",
    "            ittfn(w,eta,newf)\n",
    "        oldf = newf\n",
    "    return w\n",
    "    \n",
    "# Newton-Raphson minimization\n",
    "def newton(w,fn,gradfn,hessfn,ittfn=None):\n",
    "    oldf = fn(w)\n",
    "    eta = 1\n",
    "    while True:\n",
    "        g = gradfn(w)\n",
    "        H = hessfn(w)\n",
    "        neww = w - np.linalg.solve(H,g)\n",
    "        newf = fn(neww)\n",
    "        if newf>=oldf:\n",
    "            usedg = True\n",
    "            eta *= 2\n",
    "            while eta>1e-10:\n",
    "                neww = w - eta*g\n",
    "                newf = fn(neww)\n",
    "                if newf<oldf:\n",
    "                    break\n",
    "                eta *= 0.5\n",
    "            if eta<1e-10:\n",
    "                return w\n",
    "        else:\n",
    "            usedg = False\n",
    "        oldf = newf\n",
    "        w = neww\n",
    "        if ittfn is not None:\n",
    "            if usedg:\n",
    "                ittfn(w,eta,oldf)\n",
    "            else:\n",
    "                ittfn(w,0,oldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and check error rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one count: 34\n",
      "negative count: 172\n",
      "water\n",
      "Classified as type:  1  n times\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thetr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\thetr\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one count: 14\n",
      "negative count: 192\n",
      "fire\n",
      "Classified as type:  2  n times\n",
      "one count: 14\n",
      "negative count: 192\n",
      "grass\n",
      "Classified as type:  3  n times\n",
      "one count: 22\n",
      "negative count: 184\n",
      "normal\n",
      "Classified as type:  2  n times\n",
      "one count: 14\n",
      "negative count: 192\n",
      "electric\n",
      "Classified as type:  2  n times\n",
      "one count: 25\n",
      "negative count: 181\n",
      "flying\n",
      "Classified as type:  3  n times\n",
      "one count: 10\n",
      "negative count: 196\n",
      "ice\n",
      "Classified as type:  0  n times\n",
      "one count: 21\n",
      "negative count: 185\n",
      "bug\n",
      "Classified as type:  1  n times\n",
      "one count: 17\n",
      "negative count: 189\n",
      "poison\n",
      "Classified as type:  3  n times\n",
      "one count: 27\n",
      "negative count: 179\n",
      "psychic\n",
      "Classified as type:  6  n times\n",
      "one count: 10\n",
      "negative count: 196\n",
      "dark\n",
      "Classified as type:  0  n times\n",
      "one count: 18\n",
      "negative count: 188\n",
      "steel\n",
      "Classified as type:  4  n times\n",
      "one count: 7\n",
      "negative count: 199\n",
      "ghost\n",
      "Classified as type:  0  n times\n",
      "one count: 11\n",
      "negative count: 195\n",
      "dragon\n",
      "Classified as type:  1  n times\n",
      "one count: 8\n",
      "negative count: 198\n",
      "fairy\n",
      "Classified as type:  1  n times\n",
      "one count: 11\n",
      "negative count: 195\n",
      "rock\n",
      "Classified as type:  2  n times\n",
      "one count: 20\n",
      "negative count: 186\n",
      "ground\n",
      "Classified as type:  2  n times\n",
      "one count: 12\n",
      "negative count: 194\n",
      "fighting\n",
      "Classified as type:  0  n times\n",
      "avg:  0.08414239482200644\n",
      "['water', 'fire', 'grass', 'normal', 'electric', 'flying', 'ice', 'bug', 'poison', 'psychic', 'dark', 'steel', 'ghost', 'dragon', 'fairy', 'rock', 'ground', 'fighting']\n",
      "8.439096850861556\n"
     ]
    }
   ],
   "source": [
    "def trainlr(X,Y,lmbda):\n",
    "    w0 = np.zeros((X.shape[1],1)) # starting w at zero works well for LR, this is our theta\n",
    "    return newton(w0,lambda w : lrloss(w,X,Y,lmbda),\n",
    "                  lambda w : lrgrad(w,X,Y,lmbda),\n",
    "                  lambda w : lrhess(w,X,Y,lmbda))\n",
    "\n",
    "def lrerrorrate(X,Y,w):\n",
    "    return np.sum(Y*X@w<0)/Y.shape[0]\n",
    "\n",
    "###--------------------------------------------------------\n",
    "\n",
    "import math\n",
    "from numpy import matrix\n",
    "from numpy import dot\n",
    "import statistics\n",
    "\n",
    "#print(myw)\n",
    "\n",
    "def sigmoid(n):\n",
    "    return 1/(1 + math.exp(-n))\n",
    "\n",
    "def linear_reg(theta, x):\n",
    "    return dot(matrix.transpose(theta) , x)\n",
    "\n",
    "def calc_probabilities(X, theta):\n",
    "    sigmoid_vals = []\n",
    "    for i in range(1, X.shape[0]):\n",
    "        sigmoid_vals.append(sigmoid(linear_reg(theta[i-1:i][0], X[i-1:i].as_matrix()[0])))\n",
    "    return sigmoid_vals\n",
    "\n",
    "def true_y(X, weights):\n",
    "    sigmoids = []\n",
    "    #print(sigmoid(X@weights))\n",
    "    for val in X:\n",
    "        sigmoid_value = sigmoid(linear_reg(weights, val))\n",
    "        sigmoids.append(sigmoid_value)\n",
    "    sigmoids = np.array(sigmoids) #convert to np array\n",
    "    \n",
    "    true_y_vals = []\n",
    "    classified_as_type = 0\n",
    "    for n in sigmoids:\n",
    "        if n > 0.5:\n",
    "            true_y_vals.append(1)\n",
    "            classified_as_type += 1\n",
    "        else:\n",
    "            true_y_vals.append(-1)\n",
    "            \n",
    "    print(\"Classified as type: \", classified_as_type, \" n times\")\n",
    "    return true_y_vals\n",
    "\n",
    "###------------------------------------------------------\n",
    "\n",
    "accs = []\n",
    "myw = 0\n",
    "X_test = 0\n",
    "Y_test = 0\n",
    "mytrainX = 0\n",
    "\n",
    "true_rates = []\n",
    "\n",
    "for c_type in types:\n",
    "    X, Y, X_test, Y_test, cur_type = load_data(c_type)\n",
    "\n",
    "    lmbda = 1\n",
    "    useextrafeatures = True\n",
    "    mytrainX = X.as_matrix()\n",
    "    trainY = Y\n",
    "\n",
    "    myw = trainlr(mytrainX,trainY,lmbda)\n",
    "    #myw = (myw>1.0).astype(float)\n",
    "    #print (myw.T)\n",
    "\n",
    "    print(cur_type)\n",
    "    acc_minus = lrerrorrate(X_test,Y_test,myw)\n",
    "    accs.append(acc_minus)\n",
    "    #print(acc_minus[0])\n",
    "    \n",
    "    #print(calc_probabilities(X,theta))\n",
    "    true_ys = true_y(X_test.as_matrix(), myw)\n",
    "\n",
    "    j = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for val in Y_test:\n",
    "        if Y_test[j] == 1:\n",
    "            total+=1\n",
    "            if true_ys[j] == 1:\n",
    "                correct += 1        \n",
    "        j += 1\n",
    "    tval = 100*(correct/total)\n",
    "    if tval != 0:\n",
    "        true_rates.append(tval)\n",
    "\n",
    "\n",
    "sum = 0\n",
    "for num in accs:\n",
    "    sum += num[0]\n",
    "avg = sum / 18\n",
    "print(\"avg: \", avg)\n",
    "print(types)\n",
    "print(statistics.mean(true_rates))\n",
    "\n",
    "#types2 = []\n",
    "#u = 0\n",
    "#for val in true_rates:\n",
    "#    if val != 0:\n",
    "#        types2.append(types[u])\n",
    "#    u += 1\n",
    "#plt.barh(types2, true_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid function and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x263984afa58>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lambdas = [0.1, 0.5, 1, 2, 5]\n",
    "avg_tps = [9.403, 10.07, 14.665, 9.867, 8.439]\n",
    "\n",
    "plt.plot(lambdas, avg_tps)\n",
    "\n",
    "\n",
    "#a[a>0.5] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-fold cross validation\n",
    "Do not need to do this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xvalideval(X,Y,lmbda,extrafeatures):\n",
    "    nfold = 3\n",
    "    tX = phi(X,extrafeatures)\n",
    "    def evalfn(X,Y,eX,eY):\n",
    "        return lrerrorrate(eX,eY,trainlr(X,Y,lmbda))\n",
    "        \n",
    "    m = X.shape[0]\n",
    "    splits = np.linspace(0,m,nfold+1).astype(int)\n",
    "    v = 0\n",
    "    for low,high in zip(splits[0:-1],splits[1:]):\n",
    "        trainX = np.vstack((tX[:low,:],tX[high:,:]))\n",
    "        trainY = np.vstack((Y[:low,:],Y[high:,:]))\n",
    "        validX = tX[low:high,:]\n",
    "        validY = Y[low:high,:]\n",
    "        v +=evalfn(trainX,trainY,validX,validY)\n",
    "    return v\n",
    "\n",
    "ls = np.logspace(-4,2,10)\n",
    "xverr = ls.copy()\n",
    "bstv = None\n",
    "bste = None\n",
    "bstl = None\n",
    "for i,l in enumerate(ls):\n",
    "    xverr[i] = xvalideval(trainX,trainY,l,False)\n",
    "    if bstv is None or bstv>xverr[i]:\n",
    "        bstv = xverr[i]\n",
    "        bstl = l\n",
    "        bste = False\n",
    "plt.semilogx(ls,xverr,'b-')\n",
    "for i,l in enumerate(ls):\n",
    "    xverr[i] = xvalideval(trainX,trainY,l,True)\n",
    "    if bstv is None or bstv>xverr[i]:\n",
    "        bstv = xverr[i]\n",
    "        bstl = l\n",
    "        bste = True\n",
    "plt.semilogx(ls,xverr,'g-')\n",
    "plt.legend(['raw features','raw + binary features'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
